\documentclass[letterpaper]{article}
\usepackage[titletoc,toc,title]{appendix}

\usepackage{fancyheadings,multicol}
\usepackage{amsmath,amssymb}
\usepackage{listings}
\usepackage{color}
\usepackage{url}
\usepackage{graphicx}
\usepackage{float}
\usepackage{algorithm}
\usepackage{algpseudocode}

\graphicspath{ {figures/} }

\setlength{\textheight}{\paperheight}
\addtolength{\textheight}{-2in}
\setlength{\topmargin}{-.5in}
\setlength{\headsep}{.5in}
\addtolength{\headsep}{-\headheight}
\setlength{\footskip}{.5in}
\setlength{\textwidth}{\paperwidth}
\addtolength{\textwidth}{-2in}
\setlength{\oddsidemargin}{0in}
\setlength{\evensidemargin}{0in}
\flushbottom

\title{Semantic Role Labeling with Assistance of Neural Network Dependency Parser}
\author{Shawn Peng}


\begin{document}

\maketitle
\pagenumbering{gobble}
%	\newpage
\pagenumbering{arabic}


\section{Introduction}
In this project, I developed a rule based semantic role labeling method based on dependency parsing result. ``Semantic role labeling(SRL), sometimes also called shallow semantic parsing, is a task in natural language processing consisting of the detection of the semantic arguments associated with the predicate or verb of a sentence and their classification into their specific roles." \cite{wiki:srl} For example, given the following sentence, ``The San Francisco Examiner issued a special edition yesterday.", we would want to labeling different part of it as following,\cite{Jurafsky:2009:SLP:1214993}\\

\bigskip
\begin{tabular}{ l c c r }
	[ The San Francisco Examiner ] & issued & [ a special edition ] & [ yesterday ] \\
	ARG0 & TARGET & ARG1 & ARGM-TMP \\
\end{tabular} .\\


\begin{figure}[h]
\centering
\includegraphics[width=0.7\linewidth]{figures/nndep}
\caption{An example of dependency parsing}
\label{fig:nndep}
\end{figure}

With the dependency parsing result shown in \footnote{Images in this paper are generated by Stanford Dependency Parser Software}figure \ref{fig:nndep}, one could find the SRL arguments by the dependency like nominal subject, direct object, or nominal modifier (time modifier). The SRL is important for natural language processing(NLP) tasks and further language analysis, like information extraction\cite{Punyakanok}. The semantic roles almost always correspond to the arguments in Open IE extractions\cite{Christensen:2010:SRL:1866775.1866782}. These days, there have emerged new approaches on dependency parser, we want to see how they will help the semantic role labeling task. The method I used is different from most approaches today, which use statistical models or neural networks. In this project, I mainly used one previous achievement, "A Fast and Accurate Dependency Parser using Neural Networks"\cite{manning-EtAl:2014:P14-5} which is in the state of art. It performs great both in speed and accuracy aspects. Due to limited time, in this project I only tried to assign labels to three basic arguments in sentences, i.e. verb(V), agent(ARG0), patient(ARG1).


\section{Related Works}
For the SRL task, a lot of previous jobs have been done by directly addressing SRL problem without information from a dependency parsing. The paper Automatic Labeling of Semantic Roles (Daniel Gildea and Daniel Jurafsky, 2002)\cite{Gildea:2002:ALS:643092.643093} introduced a statistical approach to address the semantic role labeling job. It uses labels in the FrameNet dataset\cite{Baker:1998:BFP:980845.980860} and get very satisfying accuracy. Punyakanok et al., 2008 tried to solve the SRL problem only based on shallow syntactic parsing\cite{Punyakanok}. FitzGerald et al., 2015 proposed a new method to find embeddings for words, which is very useful for statistical approaches to semantic role labeling\cite{FitzGerald2015SemanticRL}. Vickrey et al., 2008 tried to simplify the sentence before the SRL process\cite{Vickrey:2008:ASS:1596324.1596373}. Some other work has been done to utilize the SRL to solve the information extraction task (Janara et al., 2010)\cite{Christensen:2010:SRL:1866775.1866782}. Beside previous works on approaches, The CoNLL-12 Shared Task provided a large human-annotated corpus of verb predicates and their arguments\cite{pradhan-etal-conll-st-2012-ontonotes}. This make it very convenient to develop and test my method.




\section{Method}
The aim of the semantic role labeling task is to discover the verbâ€“argument structure for each relation in a given input sentence. In this work, I only focus on the verb predicate and the arguments ARG0 and ARG1. My method toward the SRL task can be described as following. First, I take in the dependent relations in a sentence and try to find verbs in the sentence by looking for several key dependency types. Then I use some other relations to find the subject and object of a sentence, and also I use the type of relations to infer the role of them toward the verb. At last, I use the dependency to identify the range of the role.

\subsection{Role Range}
One problem here is that even though the verb or target role is only consisting of one word, for the agent role (ARG0) and the patient role (ARG1) they usually consist of several different words. So the question is how to locate all words for a role and get the range of it? In order to solve this, I assume that the dependencies are projective. The reason I take this assumption is that in a sentence the words used to describe one role need to stay together except few special cases. With this assumption I can follow the dependent relations to get the children of the core word if given and the children of children and so on till no more dependency left. So that's all descendants belonging to one role. On the other hand, because the sentence is projective, all words we find by this mean must be consecutive and not separated by some component that belongs to other role. This process can be described in the following algorithm \ref{alg:getrange}.


\begin{algorithm}
	\caption{}\label{alg:getrange}
	\begin{algorithmic}[1]
		\Procedure{Get Range of Role}{$d, i, allow$}
		\State $s \gets $ empty \Comment{The set of words}
		\For {each $e$ in $d$}
		\If {$i$ is the index of $e$'s governor}
		\If {$e$'s governor is itself} \Comment{The handle self recursion}
		\State continue
		\EndIf
		
		\If {regex.match(allow, e.word)} \Comment{Regual expression matching}
		\State $s \gets e$
		\State $s \gets$ Get Range of Role($d$, $e$.index, allow, filter)
		\EndIf	
		\EndIf
		\EndFor
		\State \textbf{return} $x$
		\EndProcedure
	\end{algorithmic}
\end{algorithm}


\subsection{Verb Searching}
Another main job in SRL is to identify the verbs or actions in a sentence. Now since I have the dependency information, it is fairly to utilize them to do such a job. I notice that for most cases, there are some specific relations that can leads to a verb. The most obvious one is the dependency from root, which leads us to the most important stem of a sentence. Here one case needs to be taken care of. Sometime the dependency parser first points the ``ROOT'' (capitalized) dependency to a ``quote'' token, then passes it using ``root'' (not capitalized) toward stem of the inner sentence. So, we need to check these two different root relations.\\

The next dependency I use to find predicates is conjunction. I use this because mostly conjunction are used to connect two sentences. Also the conjunction in Stanford dependency parser or say the universal dependencies represent the conjunction dependency relation by putting a dependent relation between the two stem words of two sentences. Therefore, we can just follow this relation to find our targets in a sentence with conjunction.\\

Another one can be used is the relative clause. The reason here seems to be obvious. There must be at least one main verb in a relative clause, and the ``relative clause'' dependency is pointing to this word. To explain more, this dependency is very similar to the ``root'' dependency. The reason here is very straight forward. The structure of a clause is mostly same as a sentence, so that the mechanism to refer to such a part will be basically same.\\

I also use complement clause and adverbial clause modifiers. These two cases are very similar to our previous discussed relative clause. So I don't put more explanation here.\\

Some relation I use which might be a little difficult to see at a glance is open clause complement. The universal dependencies use this dependency to describe the relation between a verb or an adjective and some other predictive or clause complement that does not have its own subject. \\

In addtion, it is also reasonable to use clausal modifier of noun to do searching. The relation is representing finite and non-finite clauses that modify a nominal. However, there is one problem to notice here. Sometime the dependent of this relation is not a verb, so that I do some check to verify this. If it is not a verb, then we just skip this dependency.\\

One last thing I'm using here is 'parataxis'. The 'parataxis' represents a parallel relation. So its case is very similar to conjunction.\\

In the searching for verbs, there is a special case that is when the verb is a ``be'' verb. In this case, the root dependent will point at the complement of the ``be'' verb, as shown in following figure \ref{fig:cop},
\begin{figure}[H]
\centering
\includegraphics[width=1\linewidth]{figures/cop}
\caption{An example of ``be'' verb}
\label{fig:cop}
\end{figure}

Here, the ``root'' dependent is pointing to the word ``sure''. What we need to do is to find the dependent word with copula (cop) dependency.

\subsection{Identification of ARG0}

Once we find a verb we can start to find its corresponding subject and object. The logic here I use to find the agent is quite similar to what I use to search for verbs. That is follow some relation to get a dependent and check for different cases. Still there is a very straight forward dependency to follow, the nominal subject. Here in the universal dependencies, the representations of active subject and passive subject are separated and using different terms to name. Therefore, if we find some nominal subject for a verb, it must be the agent of this action, assuming the dependency parsing result is correct.\\

But there are a lot of time that there is no such relation between the verb and its agent. For example in a adjective clause, its subject should refer to the subject of the main sentence. So besides the simple nominal subject case we did some more search. First, in the passive form sentences, the true agent is after a ``by'' preposition. So we also need to follow nominal modifier to search agent in a such case. The dependency parser did me a favor that it will find the nominal modifier that would be an agent and label it differently, so that I can just search for this certain type of modifiers. This is shown in the following figure \ref{fig:passive} (sentence coming from CoNLL-12 data set),

\begin{figure}[H]
\centering
\includegraphics[width=1\linewidth]{figures/passive}
\caption[]{An example for the passive case}
\label{fig:passive}
\end{figure}

Second, I trace back the conjunction and open clausal complement dependencies to find counterpart verbs, and then try to find their agent. However, sometime the previous verb is in passive form then the role will be different for the verbs and we will need to check them case by case. The previous figure also shows this. In order to find the agent of verb ``expected'' we should check its governor ``ratified'' in this case, because there is a conjunction. However, we find that here the latter verb is in passive mode, and they are having different agent.\\

The relative clause need to be handled with different logic, because the nominal subject dependent is a relative pronoun. In addition, there will always be a preceding word which is correspond to the relative pronouns and works as the true agent, so that the relative pronoun is not a proper role is such a sentence. Here one thing should be mentioned, that in this case the range of the role need to be handled slightly different. We can't follow all possible dependencies. For example in the sentence in the figure \ref{fig:relcl} (sentence example come from \cite{relcl-example}),\\
\begin{figure}[H]
\centering
\includegraphics[width=0.7\linewidth]{figures/relcl}
\caption{An example of relative clause}
\label{fig:relcl}
\end{figure}
The word pencil has a relative clause dependency toward the verb ``gave'', and this shouldn't be followed when we try to figure out the range of ARG0 for the verb ``gave''. The dependencies I found that should be allow to follow consisting of determinant, adjective modifier, compound, nominal modifier with of. There are also some other exception I ruled out, say punctuation, the case marking (for preposition), nominal subject, and copula.

\subsection{Identification of ARG1}
The case here is same to the identification of ARG0 in very large extend. One main difference is that we need change the types of dependencies to follow. Here in stead of tracking nominal subject, we change to finding direct object (in figure \ref{fig:object}), passive subject (in figure \ref{fig:passive})or complement clause (in figure \ref{fig:ccomp}).
\begin{figure}[H]
\centering
\includegraphics[width=1\linewidth]{figures/object}
\caption{An example for object dependency}
\label{fig:object}
\end{figure}
\begin{figure}[H]
\centering
\includegraphics[width=0.85\linewidth]{figures/ccomp}
\caption{An example for complement clause}
\label{fig:ccomp}
\end{figure}

Another different case is in the backtracking of governor's subject and object, for example in a conjunction relation in figure \ref{fig:passive}. This is also due to the passive case. Comparisons of whether in passive forms between dependents and governors are needed to figure out the correct semantic roles. 


\subsection{Stanford Dependency Parser}

The output of the Stanford neural network dependency parser can be in several different format (in programming level), consisting of text, conll, conllu, xml, or json (which is I use in my program). Actually this dependency parser is in a software which is a large bundle of different tools. There are plentiful information that people can get from it, like dependency, POS tag, named entries, open ie and etc. Here, in my program, I mainly used the dependency information with some auxiliary of POS tags.\\

The Stanford dependency parser using universal dependencies to represent the dependent relationship. It organizes the dependent structure as links between dependents (words) and their governors (heads). This is a tree structure for most cases, but sometime it becomes a directed acyclic graph.\\



\section{Experiment}
I develop my program based on several sections (Wall Street Journal) come from the training set of CoNLL-12 Shared Task. To calculate the accuracy, I first check whether the starting point and ending point of a role predicted are the same with true labels. Then I check whether the predicted role is for the same verb to true label. At last, I make sure that no more than one predicted role can be matched to a same role in the true labels. So, what I do is to match predicted roles with true roles by comparing the starting point, ending point, and verb reference, and make sure no overlapped matching. With this method, I get the following results on the develop data set, \\

\begin{tabular}{l r}
number of sentences :	& 3329 \\
precision : 			& 72.77\% \\
recall : 				& 60.78\% \\
\end{tabular}\\


For testing, I use the section 23 of the Wall Street Journal in the testing set of CoNLL-12 Shared Task, and getting the following result, \\

\begin{tabular}{l r}
	number of sentences :	& 1382 \\
	precision : 			& 70.15\% \\
	recall : 				& 65.64\% \\
\end{tabular}\\





\section{Conclusion and Discussion}

From the experiment, we see that this method can get reasonible result. A large portion of the missed roles is the case that the core word defining the semantic relation is not a verb but a noun. This is a problem because it will be confused with the ``be''-verb case. Putting aside this the good point for this method is that it is easy to analyze compared to the statistical approachs, including ones using neural network. However, it needs a lot of work and expert knowledge to write these rules even for the basic roles (V, ARG0, ARG1) I used.\\

For the time reason, the work in this paper is limited in many aspects. For example, I am not dealing with some cases where one sentence is separated into two by the Stanford dependency parser. Also, I skipped the embedded roles in the true labels. This is seldom the case for ARG0 and ARG1 roles. Another problem is that in the handle of relative clause case, the method now I use is not working in some cases, like when there are two clause modifies the same word.


\section{Future Work}
For the relative clause case, one could be done is to follow all type of dependencies but stay before the relative pronouns. Also we can design more rules to find relations defined by nouns.

\bibliographystyle{unsrt}
\bibliography{proj}

\newpage

\begin{appendices}

\lstset{basicstyle=\ttfamily,
	showstringspaces=false,
	commentstyle=\color{red},
	keywordstyle=\color{blue},
}

\section{Usefule Commands and Codes}
Start Stanford Dependency Parser server with the following command, \\
\lstinline [language=bash]{java -mx4g -cp "*" edu.stanford.nlp.pipeline.StanfordCoreNLPServer}.\\

In this project I used a ``Python wrapper for Stanford CoreNLP" developed by Smitha Milli to get the dependency parsing result. Python code to do dependency parsing with JSON output,

\begin{lstlisting}[breaklines=true,language=Python]
from pycorenlp import StanfordCoreNLP
nlp = StanfordCoreNLP('http://localhost:9000')
sentence = 'Put some sentence here'
output = nlp.annotate(sentence, properties={
    'annotators': 'tokenize,pos,ssplit,depparse',
    'outputFormat': 'json'
})
\end{lstlisting}





\end{appendices}


\end{document}
